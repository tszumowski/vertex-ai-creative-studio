# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile
import uuid

import cv2
import numpy as np
from google.cloud import storage
from moviepy import *
from moviepy import VideoFileClip, afx, vfx
from scipy.ndimage import gaussian_filter, map_coordinates
from scipy.special import expit
from skimage.transform import resize

from common.storage import download_from_gcs, store_to_gcs
from config.default import Default

config = Default()


def _download_videos_to_temp(video_gcs_uris: list[str], tmpdir: str) -> list[str]:
    """Downloads videos from GCS to a temporary directory."""
    local_video_paths = []
    for i, gcs_uri in enumerate(video_gcs_uris):
        video_bytes = download_from_gcs(gcs_uri)
        base_name = os.path.basename(gcs_uri)
        unique_local_filename = f"{i}_{base_name}"
        local_filename = os.path.join(tmpdir, unique_local_filename)
        with open(local_filename, "wb") as f:
            f.write(video_bytes)
        local_video_paths.append(local_filename)
        print(f"Downloaded {gcs_uri} to {local_filename}")
    return local_video_paths


def _upload_to_gcs(local_path: str, destination_folder: str, mime_type: str) -> str:
    """Uploads a local file to GCS."""
    with open(local_path, "rb") as f:
        file_bytes = f.read()

    bucket_parts = config.VIDEO_BUCKET.split("/", 1)
    bucket_name = bucket_parts[0]
    base_folder = bucket_parts[1] if len(bucket_parts) > 1 else ""

    final_folder = os.path.join(base_folder, destination_folder).strip("/")
    file_name = os.path.basename(local_path)

    final_gcs_uri = store_to_gcs(
        folder=final_folder,
        file_name=file_name,
        mime_type=mime_type,
        contents=file_bytes,
        bucket_name=bucket_name,
    )
    return final_gcs_uri


# --- Transition Functions (moviepy v2.x compatible) --- #


def crossfade(clip1, clip2, transition_duration, speed_curve="sigmoid"):
    transition_start = clip1.duration - transition_duration
    total_duration = clip1.duration + clip2.duration - transition_duration

    clip1 = clip1.copy()
    clip2 = clip2.copy()

    def sigmoid_curve(t):
        return 1 / (1 + np.exp(-10 * (t - 0.5)))

    def linear_curve(t):
        return t

    def quadratic_curve(t):
        return t**2

    def cubic_curve(t):
        return t**3

    curve_functions = {
        "sigmoid": sigmoid_curve,
        "linear": linear_curve,
        "quadratic": quadratic_curve,
        "cubic": cubic_curve,
    }
    curve_func = curve_functions[speed_curve]

    clip2 = clip2.with_start(transition_start)

    def make_frame(t):
        if t < transition_start:
            return clip1.get_frame(t)
        elif t >= clip1.duration:
            return clip2.get_frame(t - transition_start)
        else:
            frame1 = clip1.get_frame(t)
            frame2 = clip2.get_frame(t - transition_start)
            progress = (t - transition_start) / transition_duration
            weight = 1.0 - curve_func(progress)
            return (weight * frame1 + (1 - weight) * frame2).astype("uint8")

    final_clip = VideoClip(make_frame, duration=total_duration)
    final_clip.fps = clip1.fps  # Set fps for the new clip
    
    if clip1.audio and clip2.audio:
        audio1 = clip1.audio.fx(afx.fadeout, transition_duration)
        audio2 = clip2.audio.fx(afx.fadein, transition_duration).set_start(
            clip1.duration - transition_duration
        )
        final_audio = CompositeAudioClip([audio1, audio2])
        final_clip.audio = final_audio

    return final_clip


def wipe(clip1, clip2, transition_duration, direction="left-to-right"):
    width, height = clip1.size
    clip2 = clip2.resized((width, height))

    transition_start = clip1.duration - transition_duration
    total_duration = clip1.duration + clip2.duration - transition_duration

    clip2 = clip2.with_start(transition_start)

    def make_mask_frame(t):
        if t < transition_start:
            return np.ones((height, width), dtype=np.float32)
        elif t < clip1.duration:
            progress = (t - transition_start) / transition_duration
            mask = np.ones((height, width), dtype=np.float32)
            if direction == "left-to-right":
                edge_position = int(width * progress)
                if edge_position > 0:
                    mask[:, :edge_position] = 0.0
            elif direction == "right-to-left":
                edge_position = int(width * (1 - progress))
                if edge_position < width:
                    mask[:, edge_position:] = 0.0
            elif direction == "top-to-bottom":
                edge_position = int(height * progress)
                if edge_position > 0:
                    mask[:edge_position, :] = 0.0
            elif direction == "bottom-to-top":
                edge_position = int(height * (1 - progress))
                if edge_position < height:
                    mask[edge_position:, :] = 0.0
            return mask
        else:
            return np.zeros((height, width), dtype=np.float32)

    mask_clip = VideoClip(make_mask_frame, duration=total_duration, is_mask=True)
    clip1_masked = clip1.with_mask(mask_clip)

    final_clip = CompositeVideoClip([clip2, clip1_masked], size=(width, height))
    final_clip = final_clip.with_duration(total_duration)
    final_clip.fps = clip1.fps

    if clip1.audio and clip2.audio:
        audio1 = clip1.audio.fx(afx.fadeout, transition_duration)
        audio2 = clip2.audio.fx(afx.fadein, transition_duration).set_start(
            clip1.duration - transition_duration
        )
        final_audio = CompositeAudioClip([audio1, audio2])
        final_clip.audio = final_audio

    return final_clip


def dipToBlack(clip1, clip2, transition_duration, **kwargs):
    fade_duration = transition_duration / 2.0
    clip1_faded = clip1.with_effects([vfx.FadeOut(fade_duration)])
    clip2_faded = clip2.with_effects([vfx.FadeIn(fade_duration)]).with_start(
        clip1.duration - fade_duration
    )

    black_clip = ColorClip(
        size=clip1.size, color=(0, 0, 0), duration=clip1.duration + clip2.duration
    )

    final_clip = CompositeVideoClip([black_clip, clip1_faded, clip2_faded])
    final_clip.fps = clip1.fps

    if clip1.audio and clip2.audio:
        audio1 = clip1.audio.fx(afx.fadeout, fade_duration)
        audio2 = clip2.audio.fx(afx.fadein, fade_duration).set_start(
            clip1.duration - fade_duration
        )
        final_audio = CompositeAudioClip([audio1, audio2])
        final_clip.audio = final_audio

    return final_clip


def add_blur_transition(
    clip, blur_duration, max_blur_strength=1.0, reverse=False, position="end"
):
    """
    Add a gradual blur effect to the start or end of a video clip.
    """
    if blur_duration > clip.duration:
        blur_duration = clip.duration
        print(
            f"Warning: Blur duration exceeds clip duration. Setting blur duration to {blur_duration} seconds."
        )

    if position.lower() == "start":
        effect_start_time = 0
        effect_end_time = blur_duration
    else:  # 'end'
        effect_start_time = clip.duration - blur_duration
        effect_end_time = clip.duration

    def get_blur_radius(t):
        if t < effect_start_time or t > effect_end_time:
            return 0
        effect_progress = (t - effect_start_time) / blur_duration
        max_radius = 15 * max_blur_strength
        if (position.lower() == "start" and not reverse) or (
            position.lower() == "end" and reverse
        ):
            return max_radius * (1 - effect_progress)
        else:
            return max_radius * effect_progress

    def make_frame_for_blur(t):
        frame = clip.get_frame(t)
        radius = get_blur_radius(t)
        if radius > 0:
            # Apply gaussian blur with scipy
            # Blur each color channel separately
            blurred = np.zeros_like(frame)
            for i in range(3):  # RGB channels
                blurred[:, :, i] = gaussian_filter(frame[:, :, i], sigma=radius)
            return blurred
        return frame

    return VideoClip(
        make_frame=make_frame_for_blur, duration=clip.duration, fps=clip.fps
    )


def blur(clip1, clip2, transition_duration=1.0, max_blur=1.0):
    blur_duration_per_clip = transition_duration / 2
    clip1_blurred = add_blur_transition(
        clip1,
        blur_duration=blur_duration_per_clip,
        max_blur_strength=max_blur,
        reverse=False,
        position="end",
    )
    clip2_blurred = add_blur_transition(
        clip2,
        blur_duration=blur_duration_per_clip,
        max_blur_strength=max_blur,
        reverse=True,
        position="start",
    )
    return concatenate_videoclips([clip1_blurred, clip2_blurred])


# --- Main Dispatcher --- #


def process_videos(
    video_gcs_uris: list[str],
    transition: str = "concat",
    transition_duration: float = 1.0,
) -> str:
    if not video_gcs_uris or len(video_gcs_uris) < 2:
        raise ValueError("At least two videos are required.")

    with tempfile.TemporaryDirectory() as tmpdir:
        local_paths = _download_videos_to_temp(video_gcs_uris, tmpdir)
        clips = [VideoFileClip(path) for path in local_paths]

        clip1 = clips[0]
        clip2 = clips[1]

        if transition == "concat":
            final_clip = concatenate_videoclips(clips)
        elif transition == "x-fade":
            final_clip = crossfade(clip1, clip2, transition_duration)
        elif transition == "wipe":
            final_clip = wipe(clip1, clip2, transition_duration)
        elif transition == "dipToBlack":
            final_clip = dipToBlack(clip1, clip2, transition_duration)
        else:
            final_clip = concatenate_videoclips(clips)  # Default to concat

        output_filename = f"processed_{uuid.uuid4()}.mp4"
        final_clip_path = os.path.join(tmpdir, output_filename)
        final_clip.write_videofile(final_clip_path, codec="libx264")

        final_gcs_uri = _upload_to_gcs(final_clip_path, "processed_videos", "video/mp4")

        for clip in clips:
            clip.close()
        final_clip.close()

        return final_gcs_uri


# --- GIF Conversion --- #


def convert_mp4_to_gif(
    gcs_uri: str, fps: int = 10, resize_factor: float | None = None
) -> str:
    with tempfile.TemporaryDirectory() as tmpdir:
        local_path = _download_videos_to_temp([gcs_uri], tmpdir)[0]

        output_filename = f"{os.path.splitext(os.path.basename(local_path))[0]}.gif"
        output_path = os.path.join(tmpdir, output_filename)

        clip = VideoFileClip(local_path)

        if resize_factor is not None:
            clip = clip.resized(resize_factor)

        clip.write_gif(output_path, fps=fps)
        clip.close()

        final_gcs_uri = _upload_to_gcs(output_path, "generated_gifs", "image/gif")
        return final_gcs_uri
